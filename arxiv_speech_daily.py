# -*- coding: utf-8 -*-
"""
ğŸ“š arXiv è¯­éŸ³æ–¹å‘è®ºæ–‡æ—¥æŠ¥ï¼ˆHTML é‚®ä»¶ç‰ˆï¼‰
åŠŸèƒ½ï¼š
  âœ… è‡ªåŠ¨æ£€æµ‹æœ€è¿‘æ›´æ–°æ—¥æœŸ
  âœ… --date æŒ‡å®šæ—¥æœŸ
  âœ… --broad æ¨¡ç³Šæ‰©å±•åŒ¹é…
  âœ… è‡ªåŠ¨ç”Ÿæˆ Markdown & HTML é‚®ä»¶
  âœ… å¯åœ¨ GitHub Actions ä¸­æ¯å¤©è‡ªåŠ¨è¿è¡Œ + æ¨é€ + å‘ä¿¡
"""

import argparse
import arxiv
from datetime import datetime, timedelta
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.header import Header
import os

# ===== è¯­éŸ³æ–¹å‘åˆ†ç±»ä¸å…³é”®è¯ =====
CATEGORIES = {
    "ğŸ—£ï¸ Automatic Speech Recognition (ASR)": [
        "speech recognition", "ASR", "speech-to-text", "spoken language understanding",
        "speech encoder", "end-to-end ASR", "transducer", "speech transformer"
    ],
    "ğŸµ Text-to-Speech / Speech Synthesis (TTS)": [
        "text-to-speech", "speech synthesis", "vocoder", "neural vocoder",
        "voice cloning", "speech generation", "speech resynthesis", "multi-speaker TTS",
        "Flowtron", "HiFi-GAN", "WaveGlow", "Parallel WaveGAN", "WaveNet", "Seed-TTS"
    ],
    "ğŸŒ«ï¸ Diffusion / Generative Speech Models": [
        "diffusion", "speech diffusion", "generative speech", "score-based", "audio diffusion",
        "consistency model", "flow matching", "stable audio", "DiT-TTS", "E2 TTS", "CosyVoice"
    ],
    "ğŸ§  Speech Foundation / Pretrained Models": [
        "whisper", "speech foundation model", "speech pretraining", "wav2vec",
        "HuBERT", "data2vec", "speech LM", "speech large model", "speech encoder-decoder",
        "SpeechLM", "AudioLM", "SpeechGPT"
    ],
    "ğŸ§© Multimodal / Audio-Language Models": [
        "audio language model", "speech LLM", "audiollm", "speech2text", "speech2speech",
        "audio-text model", "audio captioning", "speech reasoning", "Audio-Maestro", "Audio Flamingo"
    ],
    "ğŸ­ Speaker, Emotion & Style Modeling": [
        "speaker embedding", "speaker recognition", "emotion recognition", "prosody modeling",
        "style transfer", "voice conversion", "accent conversion", "speech identity"
    ]
}

OUTPUT_FILE = "debug_papers.md"
MAX_ABSTRACT_LENGTH = 500


def fetch_papers_for_category(cat_name, keywords, date_str, broad=False):
    """æŠ“å–æŒ‡å®šæ—¥æœŸçš„è®ºæ–‡"""
    client = arxiv.Client(page_size=25, delay_seconds=1, num_retries=2)
    all_papers = []

    dt = datetime.strptime(date_str, "%Y-%m-%d")
    next_dt = dt + timedelta(days=2 if broad else 1)
    start_utc = dt.strftime("%Y%m%d") + "0000"
    end_utc = next_dt.strftime("%Y%m%d") + "0000"

    for kw in keywords:
        if broad:
            kw_q = f"(all:\"{kw}\")"
        else:
            kw_q = f"(ti:\"{kw}\" OR abs:\"{kw}\")"

        query = f"{kw_q} AND submittedDate:[{start_utc} TO {end_utc}]"
        print("ğŸ§ª Query:", query)

        search = arxiv.Search(query=query,
                              sort_by=arxiv.SortCriterion.SubmittedDate,
                              max_results=100)
        try:
            results = list(client.results(search))
            print(f"   â†’ got {len(results)} results for {kw}")
            for result in results:
                summary = (result.summary or "").strip().replace("\n", " ")
                if len(summary) > MAX_ABSTRACT_LENGTH:
                    summary = summary[:MAX_ABSTRACT_LENGTH] + "..."
                paper = {
                    "title": result.title.strip(),
                    "authors": ", ".join(a.name for a in result.authors),
                    "url": result.entry_id,
                    "summary": summary,
                }
                if not any(p["title"] == paper["title"] for p in all_papers):
                    all_papers.append(paper)
        except Exception as e:
            print("âš ï¸ Exception:", e)

    return all_papers


def find_latest(broad=False):
    """è‡ªåŠ¨æ£€æµ‹æœ€è¿‘ä¸€ä¸ªæœ‰è®ºæ–‡çš„æ—¥æœŸ"""
    today = datetime.utcnow().date()
    for i in range(1, 7):
        d = (today - timedelta(days=i)).strftime("%Y-%m-%d")
        print(f"\n== Trying {d}")
        all_res = {}
        tot = 0
        for cat, kws in CATEGORIES.items():
            papers = fetch_papers_for_category(cat, kws, d, broad=broad)
            all_res[cat] = papers
            tot += len(papers)
        if tot > 0:
            print(f"âœ… Found {d} with {tot} papers")
            return d, all_res
    return today.strftime("%Y-%m-%d"), {}


def generate_html(all_results, date_str):
    """ç”Ÿæˆ HTML é‚®ä»¶å†…å®¹"""
    html = f"""
    <html>
    <head>
        <meta charset="utf-8">
        <style>
            body {{ font-family: 'Segoe UI', Arial, sans-serif; background-color: #fafafa; color: #333; }}
            h1 {{ text-align: center; color: #2b5f9e; }}
            h2 {{ color: #444; border-left: 5px solid #2b5f9e; padding-left: 8px; }}
            .paper {{ margin-bottom: 20px; padding: 10px; background-color: #fff; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); }}
            .title {{ font-size: 16px; font-weight: bold; }}
            .authors {{ color: #555; font-size: 13px; }}
            .abstract {{ margin-top: 5px; font-size: 14px; color: #444; }}
            a {{ color: #2b5f9e; text-decoration: none; }}
            a:hover {{ text-decoration: underline; }}
        </style>
    </head>
    <body>
        <h1>ğŸ“š arXiv è¯­éŸ³æ–¹å‘è®ºæ–‡æ—¥æŠ¥</h1>
        <p style="text-align:center;">æ—¥æœŸï¼š{date_str}</p>
        <hr>
    """

    for cat, papers in all_results.items():
        if not papers:
            continue
        html += f"<h2>{cat}</h2>"
        for p in papers:
            html += f"""
            <div class="paper">
                <div class="title"><a href="{p['url']}">{p['title']}</a></div>
                <div class="authors">ğŸ‘¥ {p['authors']}</div>
                <div class="abstract">{p['summary']}</div>
            </div>
            """
    html += "<hr><p style='text-align:center;'>âœ… æ•°æ®æ¥æºï¼š<a href='https://arxiv.org'>arXiv.org</a></p></body></html>"
    return html


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--date", type=str, help="æ‰‹åŠ¨æŒ‡å®šæ—¥æœŸ (YYYY-MM-DD)")
    parser.add_argument("--broad", action="store_true", help="å¯ç”¨æ¨¡ç³ŠåŒ¹é…ä¸æ‰©å±•çª—å£")
    args = parser.parse_args()

    broad = args.broad

    if args.date:
        date_str = args.date
        print(f"ğŸ“… ä½¿ç”¨æ‰‹åŠ¨æŒ‡å®šæ—¥æœŸ: {date_str}")
        all_results = {cat: fetch_papers_for_category(cat, kws, date_str, broad=broad)
                       for cat, kws in CATEGORIES.items()}
    else:
        print("ğŸ” è‡ªåŠ¨æ£€æµ‹æœ€è¿‘æ›´æ–°æ—¥æœŸ...")
        date_str, all_results = find_latest(broad=broad)

    # ç”Ÿæˆ HTML
    html_content = generate_html(all_results, date_str)

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write(html_content)
    print(f"âœ… å·²å†™å…¥ {OUTPUT_FILE}")

    # === é‚®ä»¶å‘é€ ===
    EMAIL_SENDER = os.environ.get("EMAIL_USER")
    EMAIL_PASS = os.environ.get("EMAIL_PASS")
    EMAIL_RECEIVER = os.environ.get("EMAIL_RECEIVER", EMAIL_SENDER)

    if EMAIL_SENDER and EMAIL_PASS:
        try:
            msg = MIMEMultipart("alternative")
            msg["From"] = EMAIL_SENDER
            msg["To"] = EMAIL_RECEIVER
            msg["Subject"] = Header(f"ğŸ“š arXiv è¯­éŸ³æ–¹å‘è®ºæ–‡æ—¥æŠ¥ {date_str}", "utf-8")
            msg.attach(MIMEText(html_content, "html", "utf-8"))

            smtp_host = "smtp.gmail.com" if "gmail" in EMAIL_SENDER else "smtp.qq.com"
            with smtplib.SMTP_SSL(smtp_host, 465) as server:
                server.login(EMAIL_SENDER, EMAIL_PASS)
                server.sendmail(EMAIL_SENDER, EMAIL_RECEIVER.split(","), msg.as_string())

            print("ğŸ“§ é‚®ä»¶å‘é€æˆåŠŸï¼")
        except Exception as e:
            print(f"âš ï¸ é‚®ä»¶å‘é€å¤±è´¥ï¼š{e}")
    else:
        print("ğŸ“­ æœªæ£€æµ‹åˆ°é‚®ç®±é…ç½®ï¼Œè·³è¿‡é‚®ä»¶å‘é€ã€‚")
